import torch
from sklearn.metrics import roc_auc_score, root_mean_squared_error
import numpy as np
import copy

from model import FeatureExtractorGNN  # Import FlexibleGNN from a separate file
from noisenoise import add_noise_to_dataset
from sklearn.linear_model import LogisticRegression, LinearRegression

from supervised_functions import infer_task_type

def train_and_evaluate_linear(
    dataset,
    test_dataset,
    layer_type,
    hidden_dim,
    num_layers,
    batch_size,
    epochs,
    lr,
    t_structure,
    t_feature,
    device,
):
    """
    Train and evaluate a linear model on embeddings from the FeatureExtractorGNN.

    Args:
        dataset: PyTorch Geometric dataset for training.
        test_dataset: PyTorch Geometric dataset for evaluation.
        layer_type (str): GNN layer type to use ("gcn", "gin").
        hidden_dim (int): Hidden layer dimension.
        num_layers (int): Number of GNN layers.
        batch_size (int): Batch size (not used for linear model).
        epochs (int): Number of training epochs (not used for linear model).
        lr (float): Learning rate (not used for linear model).
        t_structure (float): Noise level for graph structure.
        t_feature (float): Noise level for node features.
        device (torch.device): Device to train on.

    Returns:
        Final test performance (mean across tasks) and task type.
    """
    # Infer task level and type
    task_level, task_type = infer_task_type(dataset)

    # Add noise to datasets
    noisy_train_dataset = add_noise_to_dataset(copy.deepcopy(dataset), t_structure, t_feature)
    noisy_test_dataset = add_noise_to_dataset(copy.deepcopy(test_dataset), t_structure, t_feature)

    # Initialize the feature extraction model
    node_in_dim = dataset.num_node_features
    edge_in_dim = dataset.num_edge_features if hasattr(dataset, "num_edge_features") else 0
    model = FeatureExtractorGNN(
        layer_type=layer_type,
        node_in_dim=node_in_dim,
        edge_in_dim=edge_in_dim,
        hidden_dim=hidden_dim,
        num_layers=num_layers,
        num_classes=hidden_dim,  # Outputs embeddings
        task_type=task_level,
    ).to(device)
    model.eval()
    with torch.no_grad():
        # Collect train embeddings
        train_embeddings = []
        train_targets = []
        for data in noisy_train_dataset:
            data = data.to(device)
            out = model(data.x.float(), data.edge_index, data.edge_attr.float(), data.batch)
            train_embeddings.append(out.cpu().numpy())
            train_targets.append(data.y.cpu().numpy())
        train_embeddings = np.vstack(train_embeddings)
        train_targets = np.vstack(train_targets)

        # Collect test embeddings
        test_embeddings = []
        test_targets = []
        for data in noisy_test_dataset:
            data = data.to(device)
            out = model(data.x.float(), data.edge_index, data.edge_attr.float(), data.batch)
            test_embeddings.append(out.cpu().numpy())
            test_targets.append(data.y.cpu().numpy())
        test_embeddings = np.vstack(test_embeddings)
        test_targets = np.vstack(test_targets)

    # Train and evaluate per task
    task_scores = []
    for task_idx in range(train_targets.shape[1]):  # Loop over tasks
        valid_train_mask = ~np.isnan(train_targets[:, task_idx])
        valid_test_mask = ~np.isnan(test_targets[:, task_idx])

        if valid_train_mask.sum() > 0 and valid_test_mask.sum() > 0:
            if task_type == "classification":
                lin_model = LogisticRegression(max_iter=5000)
                lin_model.fit(
                    train_embeddings[valid_train_mask],
                    train_targets[valid_train_mask, task_idx],
                )
                preds = lin_model.predict_proba(test_embeddings[valid_test_mask])[:, 1]
                labels = test_targets[valid_test_mask, task_idx]
                if np.unique(labels).size > 1:  # Avoid invalid ROC-AUC computation
                    score = roc_auc_score(labels, preds)
                    task_scores.append(score)
            elif task_type == "regression":
                lin_model = LinearRegression()
                lin_model.fit(
                    train_embeddings[valid_train_mask],
                    train_targets[valid_train_mask, task_idx],
                )
                preds = lin_model.predict(test_embeddings[valid_test_mask])
                labels = test_targets[valid_test_mask, task_idx]
                score = root_mean_squared_error(labels, preds)
                task_scores.append(score)

    # Return the mean score across tasks
    mean_score = np.mean(task_scores) if len(task_scores) > 0 else 0.0
    return mean_score, task_type
